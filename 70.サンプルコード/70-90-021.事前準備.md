
# 事前準備

## S3のバケット作成

- ソースデータの格納先
	- s3://knowledge-base-test-12345/source	
- Lambdaの一時的な作業スペース
	- s3://knowledge-base-test-lambda-temp
- ソースファイルにある画像など中間ファイルの格納先
	- s3://knowledge-base-test-intermerdate
## PDFファイルのアップロード

```
files/ごみの品目情報.pdf
↓
s3://knowledge-base-test-12345/source/品目情報.pdf
```
## Lambda作成

- Function name: custom_transformation
- Runtime: Python 3.12
- Architecture: x86_64
- Create function

```
import json
import boto3

bedrock = boto3.client('bedrock-runtime')
MODEL_ID = "us.anthropic.claude-sonnet-4-20250514-v1:0"

def lambda_handler(event, context):
    output_files = []
    
    # Bedrockからの入力構造に合わせてループを回す
    for input_file in event.get('inputFiles', []):
        new_chunks = []
        for chunk in input_file.get('chunks', []):
            raw_text = chunk['content']['text']
            
            try:
                # Markdown変換の呼び出し
                transformed_text = call_bedrock_transformation(raw_text)
                new_chunks.append({
                    "content": {"text": transformed_text},
                    "metadata": chunk.get('metadata', {})
                })
            except Exception as e:
                print(f"Error: {e}")
                new_chunks.append(chunk)
        
        # 変換後のファイルをリストに追加
        output_files.append({
            "fileMetadata": input_file.get('fileMetadata', {}),
            "chunks": new_chunks
        })
            
    return {"outputFiles": output_files}

def call_bedrock_transformation(text):
    body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 2048,
        "messages": [
            {
                "role": "user",
                "content": f"以下のごみ分別テキストを、品目、手数料、出し方・注意点がわかるMarkdown表形式に整理してください。解説は不要です：\n\n{text}"
            }
        ]
    })
    
    response = bedrock.invoke_model(modelId=MODEL_ID, body=body)
    response_body = json.loads(response.get('body').read())
    return response_body['content'][0]['text']
```

- **Configuration.Edit:**
	- **Memory: 512 MB**
	- **Timeout: 5min**
- **Configuration.Permissions.Role name.`My Role Name`.Click**
- **IAM.`My Role Name`.Permissions. Add permissions.Attach policies.AmazonS3ObjectLambdaExecutionRolePolicy.Add permissions**

# Knowledge Base作成

### Amazon Bedrock.Knowledge Bases.Create.Knowledge Base with vector store
- **Knowledge Base name: knowledge-base-quick-start-52nbq**
- **IAM permissions: Create and use a new service role**
- **Service role name: AmazonBedrockExecutionRoleForKnowledgeBase_52nbq**
- **Choose data source type: Amazon S3
- **`Next`**
- **Data source: knowledge-base-quick-start-cfzef-data-source**
- **Data source location: This AWS account**
- **S3 URL: s3://knowledge-base-test-12345/source**
- **Parsing strategy: Amazon Bedrock Data Automation as parser**
- **Chunking strategy: Hierarchical chunking**
	- **Max parent token size:1500**
	- **Max child token size: 300**
	- **Overlap tokens between chunks: 30(子チャンクの10%)**
- **Transformation function.Select Lambda function: custom_transformation**
- **Transformation function.S3 bucket for Lambda function: s3://knowledge-base-test-lambda-temp # Lambdaのためのテンポラリー・個別のバケット指定要**
- **`Next`**
- **Embeddings model: Titan Text Embeddings V2**
- **Additional configurations.Embeddings type: Floating-point vector embeddings**
- **Additional configurations.Vector dimensions: 1024**
- **Vector store.Vector store creation method: Quick create a new vector store**
- **Vector store.Vector store type:  Amazon OpenSearch Serverless**
- **Multimodal storage destination: s3://knowledge-base-test-12345 # イメージ抽出などのためのテンポラリー ・個別のバケット指定要**
- **Next**
- **Create Knowledge Base**

ここでは、Knowledge Base作成の処理順に注意が必要です。
実際の作業手順は、次のようになります。

Knowledge Base作成の開始
↓ 
ベクトルストア(OpenSearch Serverless)作成の開始
↓ 
Knowledge Base作成の修了

ベクトルストア(`OpenSearch Serverless`)は該当のサービスで確認できる。

`Amazon OpenSearch Service.Serverless.Collections`をクリックしてみてください。次のようにベクトルストアのコレクションが確認できます。


![](../images/opensearch_service.png)

>[注]
この段階では、一応、ナレッジベースのデータストアが作成されているだけです。
ソースシンクを実行することで実際にベクトルが生成されます。
さらに注意すべきことは、Knowledge Baseは失敗しているが、データストアだけが成功していることがあります。しならず、放置すると、課金されます。

>[注]
>Knowledge Baseを削除してもベクトルストは自動削除されません。

### Knowledge Baseとベクトルストアのシンク

ベクトルストアにデータアップロードするためには、シンク処理が必要です。

`My Knowledge Base`を選択し、`My Data source`を選択し、`Sync`を実行します。

これで、S3のPDFファイルを読み込んでベクトルストアを作成します。

![](../images/data_source.png)

Syncing→Availableになります。

### ナレッジベースをテスト

`My Knowledge Base`を選択し、テスト(`Test Konwledge Base`)が可能です。


![](../images/knowledge_base.png)

ここでは、単純検索より、回答まで作ってもらうことにします。

- **Configurantion.Retrieval and response generation: Retrieval and response generation: data sources and model**
	- **Anthropic.Claude Sonnect 4を選択**


![](../images/knowledge_base_test.png)


# 用語説明

## データタイプ
### 非構造的なデータ

- **Knowledge Base with vector store**: S3上のデータを自動でベクトル化してOpenSearch等に保存し、低コストかつ柔軟に最新情報を参照した回答（RAG）を実現するフルマネージドサービスです。
    
- **Kendra GenAI index**: 高性能なエンタープライズ検索エンジンを基盤とし、Office 365やSharePointなど多様な外部ソースの権限管理を維持したまま、セキュアに高度な生成AI回答を提供します。

### 構造的データ

**Structured data store**（構造化データストア）は、Amazon Bedrock Knowledge Basesにおいて、非構造化テキスト（PDFやマニュアル）ではなく、**データベース（RDS/PostgreSQL）上の数値や行データ**をLLMに直接クエリさせるための機能です。

3行で説明すると以下の通りです：

- **データ形式**: SQLデータベース（Amazon RDSやAurora）などの表形式データを対象とし、テキスト検索ではなく「合計」「平均」「条件比較」といった正確な集計を可能にします。
    
- **動作原理**: LLMが自然言語の質問を解釈して適切なSQL文を自動生成（Text-to-SQL）し、データベースに対して直接問い合わせを実行します。
    
- **用途**: 在庫数、売上統計、最新の予約状況など、ベクトル検索では曖昧になりがちな「正確な数値情報」に基づいた回答が必要な場合に最適です。

## ソースデータのタイプ

- Amazon S3
- Web Crawler
- Custom
- Confluence
- Saleforce
- Sharepoint

## Parsing戦略

###  Amazon Bedrock default parser（デフォルト解析器）

特別な追加料金なしで利用できる標準的な解析機能です。

- **動作**: OCR（光学文字認識）技術を用いて、ドキュメントからテキストを抽出します。
    
- **特徴**: シンプルな文書の読み取りには十分ですが、複雑な表レイアウトや図解が含まれる場合、読み取り順序が崩れたり、表の構造を維持できなかったりすることがあります。
    
- **用途**: テキスト中心の契約書、レポート、マニュアルなど。
    
### Amazon Bedrock Data Automation as parser（データ自動化解析器）

高度なAIを用いて、ドキュメントの「構造」と「マルチモーダル要素（画像・図）」を同時に解析する機能です。

- **動作**: ドキュメント内の表、図、チェックボックスなどの構造を理解したままデータを抽出します。
    
- **特徴**: **「マルチモーダル保存（Multimodal storage）」**と組み合わせて使用し、画像データも抽出しながら、より高精度なデータソースを作成できます。
    
- **用途**: 複雑なレイアウトの申請書、図表が重要な技術資料、スキャンされた低品質な書類。
    
### Foundation models as parser（基盤モデル解析器）

Claudeなどの強力なLLM（基盤モデル）そのものを解析エンジンとして使用する、最もリッチな方法です。

- **動作**: テキスト抽出の段階でLLMを呼び出し、文書の意味を汲み取りながら構造化（Markdown化など）を行います。
    
- **特徴**: **最高精度**ですが、取り込み（Sync）の際にモデル呼び出し料金が発生します。表データを「人間が読むような意味的なまとまり」として整理する力が非常に高いです。
    
- **用途**: 今回のごみ分別表のように、単なる文字抽出ではなく「この手数料はこの品目のものだ」という**意味の紐付け**が不可欠なケース。

## チャンキング戦略

### Default chunking（デフォルト・チャンキング）

AWSが推奨する標準的な設定（通常はFixed-sizeで300トークン程度、オーバーラップ20%）を自動で適用します。

- **特徴:** 迷ったらこれ。汎用性が高く、文書の前後関係をある程度維持しつつ分割します。
    
- **用途:** 一般的なレポートやブログ記事など。
    
###  Fixed-size chunking（固定サイズ・チャンキング）

指定した文字数（トークン数）で機械的に文書を区切ります。

- **特徴:** 前後の文章を少し重ねる（Overlap）ことで、文脈の断絶を防ぎます。
    
- **用途:** 構造が単純な文書。計算が速く、最も一般的に使われます。
    
### Hierarchical chunking（階層的チャンキング）

文書を「親（大まかな内容）」と「子（詳細な内容）」の2層構造で分割します。

- **特徴:** 検索時は「子」を探し、回答生成時は「親」の文脈もLLMに渡します。
    
- **用途:** **今回の「ごみ分別PDF」には最適です。** 「粗大ごみ（親）」というカテゴリの中に、「アイロン」「自転車」などの詳細（子）がある構造を維持できるため、誤回答が減ります。
    
### Semantic chunking（意味的チャンキング）

文字数ではなく、AIが「話の変わり目」を判断して区切ります。

- **特徴:** 文脈のまとまりが非常に綺麗になりますが、取り込み（Sync）に時間がかかり、コストも高めです。
    
- **用途:** 法律文書や技術論文など、一文一文の繋がりが非常に重要な場合。
    
### No chunking（チャンキングなし）

1つのファイルを1つのベクトルとして保存します。

- **特徴:** ファイルが非常に短い（1ページ未満など）場合に適しています。
    
- **用途:** 1件1回答のFAQリストや、短いメモ。
    
## 変換関数(オプション)

**Transformation function（変換関数）**とは、Amazon Bedrock Knowledge Basesがドキュメントを読み込む際、**「データをベクトル化する直前に、中身を加工・整形するためのLambda関数」**のことです。

## Embedding model

### Amazon 
- Amazon Nova Multimodal Embeddings  1.0
- Titan Embeddings G1 - Text  v1.2
- Titan Text Embeddings V2  v2.0
### Cohere 
- Embed English  v3
- Embed Multilingual  v3
- Amazon Aurora PostgreSQL Serverless
- Amazon Neptune Analytic
## Vector store
- Amazon OpenSearch Serverless
- Amazon S3 Vectors
- Amazon Aurora PostgreSQL Serverless
- Amazon Neptune Analytics

## エンベデッドタイプとベクトル次元数

「Embeddings type」と「Vector dimensions」の選択は、ナレッジベースの**「記憶の細かさ」**と**「検索スピード・コスト」**のバランスを決める非常に重要なステップです。

今回の「ごみ分別」のような、**似たような言葉（品目）が多く、正確な区別が必要なケース**における推奨設定を解説します。

###  Embeddings type（埋め込み形式）

結論から言うと、**「Floating-point vector embeddings」** を強く推奨します。

|**項目**|**Floating-point (浮動小数点)**|**Binary (バイナリ)**|
|---|---|---|
|**精度**|**非常に高い**（推奨）|低い|
|**データの保持**|文脈やニュアンスを詳細に保持|0か1に圧縮するため、詳細が消える|
|**コスト**|ストレージ消費は多いが、今回は微差|ストレージコストを大幅削減|
|**今回の適合度**|◎ 最適|△ 不向き|

- **選ぶべき理由**: ごみ分別データは「植木鉢（プラスチック製）」と「植木鉢（陶器製）」のように、言葉は似ていても出し方が全く異なるデータが密集しています。Floating-point を使うことで、こうした**微細な情報の違い**を正確にベクトル空間上で描き分けることができます。
    
### Vector dimensions（ベクトル次元数）

- **256 / 512**: データが圧縮されるため、検索スピードは速くなりますが、情報の「解像度」が落ちます。
    
- **1024**: 情報の解像度が高くなり、品目名と「30cm以上」「400円」といった付随情報の結びつきをより正確に表現できます。
    
今回のPDFは10ページ程度と非常に小規模です。次元数を最大（1024）にしても、検索速度（レイテンシ）への影響は体感できず、ストレージ料金の差も月額数円レベルです。コストを削るメリットよりも、**「正しい捨て方を一発で検索できる精度」**を優先すべきです。

    
